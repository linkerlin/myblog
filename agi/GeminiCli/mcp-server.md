---
title: AI的“触角”_模型上下文协议服务器如何赋能Gemini CLI

---

在数字世界的浩瀚星海中，人工智能正以前所未有的速度进化，从最初的计算引擎，逐步蜕变为能够理解、推理乃至创造的智慧生命。然而，即便拥有再强大的“大脑”，如果缺乏与现实世界交互的“触角”，AI的潜力也终将受限。想象一下，一位拥有百科全书般知识的智者，却无法打开一扇门，无法操作一台机器，那将是多么遗憾的场景。

🌍 **AI的“触角”：什么是MCP服务器？**

在Gemini CLI（命令行界面）的宇宙中，模型上下文协议（Model Context Protocol，简称MCP）服务器正是AI连接外部世界的“触角”和“工具箱”。它不是一个简单的软件，而是一座精心设计的桥梁，让Gemini模型能够超越其内置能力，与你的本地环境、数据库、API接口乃至任何自定义脚本进行深度互动。

> **注解：Gemini CLI**
> Gemini CLI 是一个命令行工具，它允许用户通过文本命令与Gemini AI模型进行交互。它就像一个翻译官，将你的指令传达给AI，并将AI的响应呈现给你。而MCP服务器，则让这个翻译官拥有了更多的“语言”和“技能”。

你可以把MCP服务器想象成一个拥有无数专业工具的智能机器人管家。当Gemini CLI需要完成一项特定任务，比如查询数据库、调用外部API或者执行一段复杂的本地脚本时，它不会自己去“学习”如何操作这些工具，而是通过MCP协议，向这个机器人管家发出指令。管家收到指令后，会从它的“工具箱”里找出合适的工具，执行任务，然后将结果反馈给Gemini CLI。

MCP服务器的核心能力可以概括为三点：

1.  **发现工具（Discover tools）**：它能向Gemini CLI展示自己拥有哪些工具，每种工具的功能、使用方法和所需参数都清晰明了，就像工具箱里的每把工具都贴着详细的说明标签。
2.  **执行工具（Execute tools）**：当Gemini CLI决定使用某个工具时，MCP服务器会精确地按照指令，带着正确的参数去执行它，并确保执行过程的顺畅。
3.  **访问资源（Access resources）**：虽然Gemini CLI主要侧重于工具执行，但MCP服务器也提供了访问特定数据源的能力，让AI能够获取外部信息。

通过MCP服务器，Gemini CLI的能力得到了极大的扩展。它不再仅仅是一个“思考者”，更成为了一个“行动者”，能够深入到你的本地系统，完成各种复杂的、与现实世界紧密结合的任务。这就像给AI插上了翅膀，让它的智慧能够真正落地生根，解决实际问题。

🧠 **幕后魔术：核心集成架构的奥秘**

MCP服务器与Gemini CLI的集成，并非简单的“插拔”式连接，而是一套精妙的、如同神经系统般复杂的发现与执行机制。这套系统主要由Gemini CLI核心包中的`packages/core/src/tools/`模块负责，它就像AI的“感官中枢”，负责感知、理解并协调外部工具的使用。

↳ 聚焦：**发现层（Discovery Layer）——《工具的图书馆管理员》**

想象一下，Gemini CLI就像一个求知若渴的学者，而MCP服务器则是散落在各处的专业图书馆。`mcp-client.ts`中的`discoverMcpTools()`函数，就是这位学者派遣出去的“图书馆管理员”。它的任务是：

1.  **巡视图书馆（Iterates through configured servers）**：管理员会根据`settings.json`配置文件中列出的所有“图书馆”（MCP服务器）地址，逐一进行拜访。
2.  **建立联系（Establishes connections）**：管理员会根据图书馆的“通信方式”（传输机制），选择合适的“联络工具”（Stdio、SSE或Streamable HTTP）与图书馆建立连接。
3.  **获取目录（Fetches tool definitions）**：连接成功后，管理员会向图书馆索取一份详细的“工具目录”（MCP协议定义的工具定义）。这份目录包含了每个工具的名称、功能描述和使用参数。
4.  **核对信息（Sanitizes and validates）**：管理员拿到目录后，会仔细核对每一项工具信息，确保它们符合Gemini CLI的“阅读习惯”（与Gemini API的兼容性）。任何不规范的条目都会被修正或剔除。
5.  **登记入册（Registers tools）**：最后，管理员会将这些经过核对的工具，统一登记到Gemini CLI的“全球工具注册中心”。如果遇到同名的工具，管理员还会巧妙地进行“冲突解决”，确保每个工具都有独一无二的“身份证”。

这个发现过程就像一个严谨的图书馆管理流程，确保Gemini CLI能够清晰、准确地了解所有可用的外部工具，为后续的“知识调用”做好准备。

↳ 聚焦：**执行层（Execution Layer）——《工具的指挥家》**

当Gemini模型决定要使用某个工具时，就轮到`mcp-tool.ts`中的`DiscoveredMCPTool`实例登场了。它就像一位经验丰富的“工具指挥家”，负责协调工具的实际操作：

-   **确认指令（Handles confirmation logic）**：在执行任何操作前，指挥家会根据服务器的“信任设置”和用户的“偏好”，决定是否需要向用户再次确认。这就像在进行一项重要操作前，会先问一句：“您确定要这样做吗？”
-   **管理执行（Manages tool execution）**：一旦确认，指挥家就会精确地将Gemini模型提供的参数传递给MCP服务器，启动工具的执行。
-   **处理反馈（Processes responses）**：工具执行完毕后，指挥家会接收并处理返回的结果，将其格式化，一部分用于Gemini模型的上下文理解，另一部分则以用户友好的方式展示给用户。
-   **维护状态（Maintains connection state）**：指挥家还会持续关注与MCP服务器的连接状态，确保通信的稳定，并处理可能出现的超时情况。

这整个执行过程，就像一位技艺高超的指挥家，不仅要理解乐谱（工具指令），还要协调乐团（MCP服务器和工具），最终奏出美妙的乐章（任务结果）。

↳ 聚焦：**传输机制（Transport Mechanisms）——《通信的艺术》**

为了实现Gemini CLI与MCP服务器之间的无缝沟通，系统支持多种“通信方式”，每种方式都有其独特的适用场景：

-   **Stdio传输（Stdio Transport）**：这是一种最直接的通信方式，就像两个人在同一个房间里，通过“喊话”和“听取”来交流。Gemini CLI会启动一个子进程来运行MCP服务器，然后通过标准输入（stdin）和标准输出（stdout）进行数据交换。
-   **SSE传输（SSE Transport）**：SSE（Server-Sent Events）是一种服务器向客户端“单向广播”的通信方式。就像一个电台，MCP服务器会持续向Gemini CLI发送事件流，而Gemini CLI则负责接收。这适用于服务器需要主动推送信息给客户端的场景。
-   **Streamable HTTP传输（Streamable HTTP Transport）**：这种方式利用HTTP协议进行通信，但支持数据流式传输。它更像是在互联网上进行视频通话，数据可以持续不断地传输，适用于需要大量数据交换的场景。

这些多样化的传输机制，确保了Gemini CLI能够根据MCP服务器的部署方式和通信需求，选择最有效、最稳定的连接方式，从而构建起一个灵活而强大的AI“感官网络”。

🛠️ **搭建AI的“工具箱”：MCP服务器配置指南**

要让Gemini CLI找到并使用你的MCP服务器，你需要在`settings.json`文件中进行一番精心的配置。这个文件就像是Gemini CLI的“使用手册”，告诉它去哪里找工具，以及如何使用这些工具。你可以在全局的`~/.gemini/settings.json`文件中配置，也可以在你的项目根目录下的`.gemini/settings.json`文件中进行配置。

> **注解：settings.json**
> `settings.json`是Gemini CLI的配置文件，用于存储各种用户偏好、插件设置和服务器连接信息。它采用JSON格式，结构清晰，易于编辑。

在`settings.json`中，你需要添加一个`mcpServers`配置块，它是一个JSON对象，可以包含多个MCP服务器的配置，每个服务器都有一个唯一的名称作为键。

```json
{
  // ...文件中的其他配置对象
  "mcpServers": {
    "serverName": {
      "command": "path/to/server", // Stdio传输的执行路径
      "args": ["--arg1", "value1"], // 命令行参数
      "env": {
        "API_KEY": "$MY_API_TOKEN" // 环境变量，支持引用系统变量
      },
      "cwd": "./server-directory", // 工作目录
      "timeout": 30000, // 请求超时时间（毫秒）
      "trust": false // 是否跳过工具调用确认
    }
  }
}
```

↳ 聚焦：**配置属性详解**

每个服务器配置都支持以下属性：

**必需属性（三选一）**：

-   **`command` (string)**：如果你使用Stdio传输，这里填写MCP服务器可执行文件的路径。
-   **`url` (string)**：如果你使用SSE传输，这里填写SSE端点的URL，例如`"http://localhost:8080/sse"`。
-   **`httpUrl` (string)**：如果你使用Streamable HTTP传输，这里填写HTTP流式端点的URL。

**可选属性**：

-   **`args` (string[])**：当使用Stdio传输时，这里可以指定传递给服务器的命令行参数。
-   **`headers` (object)**：当使用`url`或`httpUrl`时，这里可以设置自定义的HTTP请求头，例如用于身份验证的`Authorization`。
-   **`env` (object)**：为MCP服务器进程设置环境变量。这些值可以引用系统环境变量，例如`"$VAR_NAME"`或`"${VAR_NAME}"`。这对于传递API密钥等敏感信息非常有用。
-   **`cwd` (string)**：当使用Stdio传输时，这里指定MCP服务器的工作目录。
-   **`timeout` (number)**：设置请求的超时时间，单位是毫秒。默认值是600,000毫秒（10分钟）。
-   **`trust` (boolean)**：这是一个非常重要的安全设置。如果设置为`true`，Gemini CLI将跳过该服务器所有工具调用的确认对话框。**请务必谨慎使用，只对你完全信任的服务器启用此选项。**

↳ 聚焦：**配置示例**

为了更好地理解，我们来看看几种常见的配置场景：

-   **Python MCP服务器（Stdio）**：
    ```json
    {
      "mcpServers": {
        "pythonTools": {
          "command": "python",
          "args": ["-m", "my_mcp_server", "--port", "8080"],
          "cwd": "./mcp-servers/python",
          "env": {
            "DATABASE_URL": "$DB_CONNECTION_STRING",
            "API_KEY": "${EXTERNAL_API_KEY}"
          },
          "timeout": 15000
        }
      }
    }
    ```
    这个配置告诉Gemini CLI，有一个名为`pythonTools`的MCP服务器，它是一个Python程序，通过`python -m my_mcp_server --port 8080`命令启动，工作目录在`./mcp-servers/python`，并且会从系统环境变量中获取数据库连接字符串和API密钥。

-   **Node.js MCP服务器（Stdio）**：
    ```json
    {
      "mcpServers": {
        "nodeServer": {
          "command": "node",
          "args": ["dist/server.js", "--verbose"],
          "cwd": "./mcp-servers/node",
          "trust": true
        }
      }
    }
    ```
    这里配置了一个Node.js服务器，启动命令是`node dist/server.js --verbose`，工作目录在`./mcp-servers/node`。值得注意的是，`"trust": true`意味着Gemini CLI将完全信任这个服务器，不再进行任何工具调用确认。

-   **Docker容器化MCP服务器**：
    ```json
    {
      "mcpServers": {
        "dockerizedServer": {
          "command": "docker",
          "args": [
            "run",
            "-i",
            "--rm",
            "-e",
            "API_KEY",
            "-v",
            "${PWD}:/workspace",
            "my-mcp-server:latest"
          ],
          "env": {
            "API_KEY": "$EXTERNAL_SERVICE_TOKEN"
          }
        }
      }
    }
    ```
    这个例子展示了如何将一个Docker容器作为MCP服务器。Gemini CLI会执行`docker run`命令来启动容器，并将当前目录挂载到容器内部，同时传递API密钥环境变量。

-   **HTTP-based MCP服务器**：
    ```json
    {
      "mcpServers": {
        "httpServer": {
          "httpUrl": "http://localhost:3000/mcp",
          "timeout": 5000
        }
      }
    }
    ```
    如果你的MCP服务器是一个HTTP服务，你可以直接指定其URL。Gemini CLI会通过HTTP协议与其通信。

-   **带自定义HTTP头的HTTP-based MCP服务器**：
    ```json
    {
      "mcpServers": {
        "httpServerWithAuth": {
          "httpUrl": "http://localhost:3000/mcp",
          "headers": {
            "Authorization": "Bearer your-api-token",
            "X-Custom-Header": "custom-value",
            "Content-Type": "application/json"
          },
          "timeout": 5000
        }
      }
    }
    ```
    这个例子在HTTP通信中加入了自定义的请求头，这对于需要身份验证或特定内容类型的API非常有用。

通过这些灵活的配置选项，你可以将各种类型的MCP服务器无缝集成到Gemini CLI中，为AI提供一个丰富多样的“工具生态系统”。

🔍 **寻宝之旅：工具发现的深度解析**

当Gemini CLI启动时，它会立即踏上一段“寻宝之旅”，去发现并注册所有配置好的MCP服务器提供的工具。这并非简单的列表读取，而是一个严谨而复杂的过程，确保每个工具都能被正确识别和使用。

↳ 聚焦：**服务器迭代与连接**

这段旅程从逐一拜访`mcpServers`配置中的每个服务器开始：

1.  **状态追踪**：每个服务器的“状态”都会被标记为`CONNECTING`，表示正在尝试连接。
2.  **传输选择**：Gemini CLI会根据配置中提供的`httpUrl`、`url`或`command`，智能地选择最合适的“交通工具”（`StreamableHTTPClientTransport`、`SSEClientTransport`或`StdioClientTransport`）来建立连接。
3.  **连接建立**：客户端会尝试在设定的超时时间内与服务器建立连接。
4.  **错误处理**：如果连接失败，系统会记录错误信息，并将服务器状态设置为`DISCONNECTED`，表示这个“宝藏点”暂时无法访问。

↳ 聚焦：**工具发现**

一旦连接成功，真正的“寻宝”就开始了：

1.  **工具列表**：客户端会向MCP服务器请求一份“宝藏清单”（工具列表）。
2.  **模式验证**：清单上的每个工具，其“功能声明”（function declaration）都会经过严格的“模式验证”，确保其符合规范。
3.  **名称净化**：工具的名称也会被“净化”，去除所有不符合Gemini API要求的字符（非字母数字、下划线、点、连字符），并用下划线替换。如果名称过长（超过63个字符），还会进行截断处理，确保其简洁性。

↳ 聚焦：**冲突解决**

在“寻宝”过程中，可能会遇到不同服务器提供同名“宝藏”的情况。Gemini CLI有一套巧妙的“冲突解决”机制：

1.  **先到先得**：第一个注册同名工具的服务器，将获得该工具的“原始名称”。
2.  **自动加前缀**：后续发现的同名工具，其名称会自动加上服务器名称作为前缀，例如`serverName__toolName`，以示区分。
3.  **注册中心**：工具注册中心会维护一个映射表，清晰地记录每个服务器及其对应的工具。

↳ 聚焦：**模式处理**

工具参数的“模式”（schema）也会经过一番“精修”，以确保与Gemini API的兼容性：

-   **移除冗余**：`$schema`属性和`additionalProperties`等冗余信息会被移除。
-   **兼容性调整**：`anyOf`中带有`default`值的属性，其默认值会被移除，以适应Vertex AI的兼容性要求。
-   **递归处理**：这种处理会递归地应用于嵌套的模式中，确保所有层级的模式都符合规范。

↳ 聚焦：**连接管理**

“寻宝之旅”结束后，Gemini CLI会进行一番“整理”：

-   **持久连接**：成功注册工具的服务器，其连接会保持持久化，以便后续的工具调用。
-   **清理**：那些没有提供任何可用工具的服务器，其连接会被自动关闭，避免资源浪费。
-   **状态更新**：所有服务器的最终状态都会被设置为`CONNECTED`或`DISCONNECTED`，清晰地展示了“寻宝”的结果。

整个工具发现过程，就像一位经验丰富的侦探，不仅要找到线索（工具），还要核实其真实性，解决潜在的冲突，并最终将所有有用的信息整理归档，为AI的“行动”做好充分准备。

🚀 **驾驭工具：MCP工具的执行艺术**

当Gemini模型在思考和推理之后，决定要“动手”使用某个MCP工具时，一场精密的“执行艺术”便拉开了序幕。这不仅仅是简单地调用一个函数，更包含了复杂的确认流程、参数准备和结果处理。

↳ 聚焦：**工具调用**

一切始于Gemini模型生成的一个`FunctionCall`指令。这个指令就像一张“任务卡”，上面清晰地写着：

-   **工具名称**：要使用的工具叫什么名字（可能带有前缀）。
-   **参数**：执行这个工具需要哪些参数，这些参数以JSON对象的形式呈现，并且严格匹配工具的参数模式。

↳ 聚焦：**确认流程**

在工具真正执行之前，`DiscoveredMCPTool`会启动一套精密的“确认流程”。这就像在进行一项重要操作前，系统会再次向你确认，以确保安全和控制：

-   **信任豁免**：如果MCP服务器在配置时被设置为`"trust": true`，那么所有来自该服务器的工具调用都将直接跳过确认，就像你对一个老朋友完全信任，无需多言。
-   **动态白名单**：系统内部维护着一个“白名单”，可以动态地添加信任的服务器或特定的工具。
    -   **服务器级别**：如果你信任某个服务器的所有工具，那么该服务器的所有工具都会被列入白名单。
    -   **工具级别**：如果你只信任某个服务器的特定工具，那么只有这个工具会被列入白名单。
-   **用户选择处理**：当需要确认时，用户会看到一个对话框，可以选择：
    -   **本次执行**：只执行这一次。
    -   **始终允许此工具**：将该工具添加到工具级别的白名单。
    -   **始终允许此服务器**：将该服务器添加到服务器级别的白名单。
    -   **取消**：中止执行。

这个确认流程是Gemini CLI安全机制的重要组成部分，它赋予了用户对AI行为的最终控制权，避免了潜在的误操作或安全风险。

↳ 聚焦：**执行**

一旦通过确认（或被信任豁免），工具便进入了真正的执行阶段：

1.  **参数准备**：Gemini模型提供的参数会再次与工具的模式进行严格验证，确保数据的正确性和完整性。
2.  **MCP调用**：底层的`CallableTool`会向MCP服务器发出调用指令，其中包含了原始的服务器工具名称和准备好的参数。
3.  **响应处理**：MCP服务器执行工具并返回结果后，Gemini CLI会对其进行处理，一部分原始响应用于语言模型的上下文理解，另一部分则被格式化为用户友好的输出。

↳ 聚焦：**响应处理**

工具执行的结果会包含两部分，分别服务于AI和用户：

-   **`llmContent`**：这是原始的响应内容，直接提供给语言模型，用于其后续的推理和生成。
-   **`returnDisplay`**：这是经过格式化的输出，通常以Markdown代码块中的JSON形式呈现，方便用户阅读和理解。

整个工具执行流程，就像一位精准的指挥家，不仅要确保乐谱（指令）的正确性，还要协调乐团（MCP服务器和工具）的演奏，最终呈现出完美的乐章（执行结果），同时还要兼顾听众（用户）的感受。

📊 **掌控全局：交互与故障排除**

拥有了强大的MCP服务器，如何才能更好地管理和监控它们呢？Gemini CLI提供了一系列命令和状态追踪机制，让你能够像一位经验丰富的工程师一样，随时掌控AI的“工具箱”运行状况。

↳ 聚焦：**/mcp 命令：你的控制中心**

`/mcp`命令是你的MCP服务器控制中心，它能提供关于MCP服务器设置的全面信息：

```bash
/mcp
```

执行这个命令，你将看到：

-   **服务器列表**：所有已配置的MCP服务器一览无余。
-   **连接状态**：每个服务器的实时连接状态，可能是`CONNECTED`（已连接）、`CONNECTING`（正在连接）或`DISCONNECTED`（已断开）。
-   **服务器详情**：每个服务器的配置摘要，但会排除敏感数据，确保信息安全。
-   **可用工具**：每个服务器提供的工具列表，以及它们的简要描述。
-   **发现状态**：整个工具发现过程的总体状态，例如`COMPLETED`（已完成）。

**示例 `/mcp` 输出解读**：

```
MCP Servers Status:

📡 pythonTools (CONNECTED)
  Command: python -m my_mcp_server --port 8080
  Working Directory: ./mcp-servers/python
  Timeout: 15000ms
  Tools: calculate_sum, file_analyzer, data_processor

🔌 nodeServer (DISCONNECTED)
  Command: node dist/server.js --verbose
  Error: Connection refused

🐳 dockerizedServer (CONNECTED)
  Command: docker run -i --rm -e API_KEY my-mcp-server:latest
  Tools: docker__deploy, docker__status

Discovery State: COMPLETED
```

从这个输出中，你可以清晰地看到：`pythonTools`和`dockerizedServer`都已成功连接并提供了工具，而`nodeServer`则处于断开状态，并给出了连接被拒绝的错误信息。`Discovery State: COMPLETED`则表明整个发现过程已经完成。

↳ 聚焦：**工具使用**

一旦MCP工具被发现并注册，它们就如同Gemini CLI的内置工具一样，可以被Gemini模型自动调用。模型会根据你的请求，智能地选择合适的工具，并在必要时（除非服务器被信任）弹出确认对话框，执行工具并以用户友好的格式显示结果。

↳ 聚焦：**状态监控**

MCP集成会追踪两种关键状态，帮助你了解系统的健康状况：

-   **服务器状态（`MCPServerStatus`）**：
    -   `DISCONNECTED`：服务器未连接或存在错误。
    -   `CONNECTING`：正在尝试连接。
    -   `CONNECTED`：服务器已连接并准备就绪。
-   **发现状态（`MCPDiscoveryState`）**：
    -   `NOT_STARTED`：发现过程尚未开始。
    -   `IN_PROGRESS`：正在进行服务器发现。
    -   `COMPLETED`：发现过程已完成（无论是否有错误）。

↳ 聚焦：**常见问题与解决方案**

在实际使用中，你可能会遇到一些问题。以下是一些常见症状及其故障排除方法：

-   **服务器无法连接**：
    -   **症状**：服务器显示`DISCONNECTED`状态。
    -   **排查**：检查`command`、`args`和`cwd`配置是否正确；手动运行服务器命令确认其是否能正常启动；检查依赖项是否安装；查看CLI输出中的错误日志；确认CLI是否有执行服务器命令的权限。
-   **未发现工具**：
    -   **症状**：服务器已连接但没有工具可用。
    -   **排查**：确认你的服务器是否实际注册了工具；检查服务器是否正确实现了MCP工具列表协议；查看服务器的错误日志（stderr输出）；手动测试服务器的工具发现端点。
-   **工具无法执行**：
    -   **症状**：工具已发现但在执行时失败。
    -   **排查**：验证工具是否接受预期的参数；检查输入模式是否是有效的JSON Schema；确认工具是否抛出了未处理的异常；考虑增加`timeout`设置。
-   **沙盒兼容性问题**：
    -   **症状**：启用沙盒后MCP服务器失败。
    -   **解决方案**：使用基于Docker的服务器，将所有依赖项打包在容器中；确保服务器可执行文件在沙盒环境中可访问；配置沙盒以允许必要的网络连接；验证所需的环境变量是否已正确传递。

↳ 聚焦：**调试技巧**

-   **启用调试模式**：使用`--debug`参数运行CLI，获取详细的输出信息。
-   **检查stderr**：MCP服务器的stderr输出会被捕获并记录（INFO消息会被过滤）。
-   **隔离测试**：在集成之前，独立测试你的MCP服务器。
-   **增量设置**：从简单的工具开始，逐步添加复杂功能。
-   **频繁使用 `/mcp`**：在开发过程中，经常使用`/mcp`命令监控服务器状态。

通过这些监控、排查和调试技巧，你可以确保MCP服务器的稳定运行，让Gemini CLI的“工具箱”始终保持最佳状态。

⚠️ **智者之鉴：重要注意事项**

在享受MCP服务器带来的强大功能时，我们也要像一位智者一样，时刻保持警惕，关注其潜在的风险和最佳实践。

↳ 聚焦：**安全考量**

-   **信任设置**：`trust`选项会绕过所有确认对话框。这就像把家门钥匙完全交给了一个人。**请务必谨慎使用，只对你完全控制且高度信任的服务器启用此选项。**
-   **访问令牌**：在配置包含API密钥或令牌的环境变量时，务必注意安全性。这些敏感信息一旦泄露，可能造成严重后果。
-   **沙盒兼容性**：当使用沙盒时，确保MCP服务器在沙盒环境中是可用的，并且沙盒的配置不会阻碍其正常运行。
-   **私有数据**：使用范围过广的个人访问令牌可能导致信息在不同代码库之间泄露，请务必限制其权限范围。

↳ 聚焦：**性能与资源管理**

-   **连接持久性**：Gemini CLI会与成功注册工具的服务器保持持久连接。这减少了重复连接的开销，但同时也意味着服务器需要保持运行。
-   **自动清理**：对于那些没有提供任何可用工具的服务器，其连接会被自动关闭，避免不必要的资源占用。
-   **超时管理**：根据你的服务器响应特性，合理配置`timeout`时间，避免因长时间等待而导致的性能问题。
-   **资源监控**：MCP服务器作为独立的进程运行，会消耗系统资源。请务必监控其CPU、内存等资源使用情况，确保系统稳定。

↳ 聚焦：**模式兼容性**

-   **属性剥离**：系统会自动移除某些模式属性（如`$schema`、`additionalProperties`），以确保与Gemini API的兼容性。
-   **名称净化**：工具名称会自动净化，以满足API要求。
-   **冲突解决**：不同服务器之间的工具名称冲突会通过自动加前缀的方式解决。

这些注意事项，就像是AI“工具箱”的使用说明书，提醒我们在享受便利的同时，也要遵循规范，确保安全、高效和稳定。

**结语：AI的无限可能**

模型上下文协议服务器，如同为Gemini CLI插上了一双能够触及现实世界的“翅膀”，让AI不再仅仅是停留在云端的智慧，而是能够深入到我们的本地环境，操作工具，解决实际问题的“行动者”。从发现工具的“图书馆管理员”，到执行工具的“指挥家”，再到掌控全局的“工程师”，MCP服务器的每一个环节都充满了精妙的设计和严谨的考量。

它不仅扩展了AI的能力边界，更在安全、性能和易用性之间找到了完美的平衡。未来，随着更多MCP服务器的涌现，AI将能够连接更广阔的生态系统，掌握更丰富的专业技能，真正成为我们工作和生活中的得力助手。

那么，你是否已经准备好，与Gemini CLI一起，探索AI的无限可能，共同开启一个全新的智能时代？

**参考文献**

1.  Google Gemini CLI Documentation. (n.d.). *Model Context Protocol (MCP) Servers*.
2.  OpenAI. (2023). *Function Calling*.
3.  Microsoft. (n.d.). *Semantic Kernel Documentation*.
4.  LangChain. (n.d.). *Tools*.
5.  Hugging Face. (n.d.). *Transformers Agents*.
